---
title: "Hadoop 설치"
excerpt: "Hadoop"

categories:
  - Big Data
tags:
  - Big Data
classes: wide
last_modified_at: 2019-05-31T12:49:00-05:00
---

> 포기하지 않기. 

***

The Google File System(GFS)을 기반으로 하여 하둡 분산 파일 시스템(HDFS)가 개발되었음. 


- 기본 구조 

  - HDFS는 Master-Slave 구조로 되어 있다. 여기에서 가장 중요한 부분은 Master의 안정성을 보장할 수 있는 구조가 되어야 한다. 
  - Master-Slave 구조라는 것은 Slave 가 n 대로 확장해 나가는 구조라고 생각하면 된다. 


- 구글 플랫폼의 기본 요건

  - 한대의 고가 장비보다 여러 대의 저가 장비가 낫다. 
  - 데이터는 분산 저장한다. 
  - 시스템은 언제든 죽을 수 있다. 
  - 시스템 확장이 쉬워야 한다. 


- 하둡 특성 

  - 수천대 이상의 리눅스 기반 범용 서버들을 하나의 클러스터로 사용 
  - 마스터 - 슬레이브 구조 
  - 파일은 블록(block) 단위로 저장 
  - 블록 데이터의 복제본 유지로 인한 신뢰성 보장 ( 기본 3개의 복제본 )
  - 높은 내 고장성 ( Fault Tolerance )
  - 데이터 처리의 지역성 보장 

- 하둡 Cluster 네트워크 / 데몬 구성 

![](https://keepinmindsh.github.io/lines/assets/img/hadoop_cluster.png){: .align-center}

하둡의 경우, 여러대의 구성은 큰 의미가 없고 최소 몇십대 이상의 구성으로 구축하여 사용 가능함. 여러대의 서버를 하나의 클러스터로 구성되게 되어 있음. 



> 참조 : <https://www.youtube.com/watch?v=pixlGPc4vbA&list=PL9mhQYIlKEheGLT1V_PEby_I9pOXr1o3r&index=3> [하둡 분산 파일 시스템의 이해(1) - T 아카데미]
