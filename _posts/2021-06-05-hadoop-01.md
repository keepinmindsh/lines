---
title: "Hadoop 설치"
excerpt: "Hadoop"

categories:
  - Big Data
tags:
  - Big Data
classes: wide
last_modified_at: 2019-05-31T12:49:00-05:00
---

> 포기하지 않기. 

***

The Google File System(GFS)을 기반으로 하여 하둡 분산 파일 시스템(HDFS)가 개발되었음. 


- 기본 구조 

  - HDFS는 Master-Slave 구조로 되어 있다. 여기에서 가장 중요한 부분은 Master의 안정성을 보장할 수 있는 구조가 되어야 한다. 
  - Master-Slave 구조라는 것은 Slave 가 n 대로 확장해 나가는 구조라고 생각하면 된다. 


- 구글 플랫폼의 기본 요건

  - 한대의 고가 장비보다 여러 대의 저가 장비가 낫다. 
  - 데이터는 분산 저장한다. 
  - 시스템은 언제든 죽을 수 있다. 
  - 시스템 확장이 쉬워야 한다. 


- 하둡 특성 

  - 수천대 이상의 리눅스 기반 범용 서버들을 하나의 클러스터로 사용 
  - 마스터 - 슬레이브 구조 
  - 파일은 블록(block) 단위로 저장 
  - 블록 데이터의 복제본 유지로 인한 신뢰성 보장 ( 기본 3개의 복제본 )
  - 높은 내 고장성 ( Fault Tolerance )
  - 데이터 처리의 지역성 보장 

- 하둡 Cluster 네트워크 / 데몬 구성 

![](https://keepinmindsh.github.io/lines/assets/img/hadoop_cluster.png){: .align-center}

하둡의 경우, 여러대의 구성은 큰 의미가 없고 최소 몇십대 이상의 구성으로 구축하여 사용 가능함. 여러대의 서버를 하나의 클러스터로 구성되게 되어 있음. 

- DN : Data Node 
- TT : Task Tracker

**하둡에서 블록이란?**     

- 하나의 파일을 여러 개의 Block으로 저장
- 설정에 의해 하나의 Block은 64MB 또는 128MB 등의 큰 크기로 나누어 저장 
- 블록 크키가 128MB 보다 적은 경우는 실제 크기 만큼만 용량을 차지함 

**하둡에서 블록(Block) 하나의 크기가 큰 이유는?**

- HDFS의 블록은 128MB와 같이 매우 큰 단위 
- 블록이 큰 이유는 탐색 비용을 최소화 할 수 있기 때문 
- 블록이 크면 하드 디스크에서 블록의 시작점을 탐색하는 데 걸리는 시간을 줄일 수 있고, 네트워크를 통해 데이터를 전송하는데 더 많은 시간을 할당이 가능함. 

하둡은 자체적으로 들어온 데이터를 128MB 기준으로 분리하여 저장 처리한다. 마스터 서버에는 데이터를 저장하지 않음. 

![](https://keepinmindsh.github.io/lines/assets/img/hadoop_structure_001.png){: .align-center}





> 참조 : <https://www.youtube.com/watch?v=pixlGPc4vbA&list=PL9mhQYIlKEheGLT1V_PEby_I9pOXr1o3r&index=3> [하둡 분산 파일 시스템의 이해(1) - T 아카데미]
